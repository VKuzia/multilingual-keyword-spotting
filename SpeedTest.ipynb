{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0b09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f268640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ubrana: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14525/14525 [10:54<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 53s, sys: 1min 52s, total: 1h 2min 45s\n",
      "Wall time: 10min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_clips = \"dataset/multilingual_spoken_words/mswc_microset_wav/pl/clips\"\n",
    "path_to_output = \"dataset/multilingual_spoken_words/mswc_microset_wav/pl/clips_tensors\"\n",
    "\n",
    "transform = torchaudio.transforms.MelSpectrogram(n_mels=49, hop_length=401, power=0.75)\n",
    "\n",
    "pbar = tqdm(os.listdir(path_to_clips))\n",
    "for label in pbar:\n",
    "    pbar.set_description(label)\n",
    "    os.makedirs(f'{path_to_output}/{label}', exist_ok=True)\n",
    "    for audio in os.listdir(path_to_clips + \"/\" + label):\n",
    "        src = f'{path_to_clips}/{label}/{audio}'\n",
    "        dest = f'{path_to_output}/{label}/{audio}'.replace(\".wav\", \".pt\")\n",
    "        waveform, _ = torchaudio.load(src)\n",
    "        target = torch.zeros(49, 40)\n",
    "        transformed = transform(waveform)[0]\n",
    "        target[:, :min(transformed.shape[1], 40)] = transformed[:, :min(transformed.shape[1], 40)]\n",
    "#         if spectrogram.shape != (49, 40):\n",
    "#             display(\"atata \" + f'{src} -> {spectrogram.shape}')\n",
    "#         print(spectrogram)\n",
    "#         break\n",
    "        torch.save(target.cuda(), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6b3a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_wav = path_to_clips\n",
    "path_to_tensors = path_to_output\n",
    "\n",
    "def test_loading(func, is_tensors):\n",
    "    path = path_to_tensors if is_tensors else path_to_wav\n",
    "    for label in tqdm(os.listdir(path)):\n",
    "        for audio in os.listdir(f'{path}/{label}'):\n",
    "            filepath = f'{path}/{label}/{audio}'\n",
    "            func(filepath)\n",
    "            \n",
    "def load_tensor(filepath):\n",
    "    spectrogram = torch.load(filepath)\n",
    "    return\n",
    "\n",
    "def load_wav(filepath):\n",
    "    waveform, _ = torchaudio.load(filepath)\n",
    "    spectrogram = transform(waveform)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f9d65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15900/15900 [08:08<00:00, 32.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 43s, sys: 45.1 s, total: 45min 28s\n",
      "Wall time: 8min 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_loading(load_wav, is_tensors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93dc5b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15900/15900 [05:21<00:00, 49.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 1min 22s, total: 4min 18s\n",
      "Wall time: 5min 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_loading(load_tensor, is_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61aae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
